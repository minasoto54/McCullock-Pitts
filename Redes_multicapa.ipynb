{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Redes multicapa",
      "authorship_tag": "ABX9TyNtyW9MBQ3XvQ6bDZoFYAAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minasoto54/McCullock-Pitts/blob/main/Redes_multicapa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PRESENTACIÓN\n",
        "# REDES MULTICAPA"
      ],
      "metadata": {
        "id": "PEugKRmGwnJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebv6_6ZiwF63",
        "outputId": "6f103527-d37d-4541-b7a1-a769be00daba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   =  =  =  =  =  =\n",
            "1️  RED NEURONAL MULTICAPA - XOR\n",
            "  =  =  =  =  =  =\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Entrenamiento completado \n",
            "Predicciones: [0 1 0 0]\n",
            "Clases reales: [0 1 1 0]\n",
            "\n",
            "   =   =   =   =   =   =\n",
            "2️  CLASIFICACIÓN DE LA FLOR DE IRIS\n",
            "   =   =   =   =   =   =\n",
            "Exactitud en prueba: 100.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "   =   =   =   =   =   =\n",
            "3️  CLASIFICACIÓN DE UN CANDIDATO A UN EMPLEO\n",
            "   =   =   =   =   =   =\n",
            "Exactitud en prueba: 95.00%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9787    0.9200    0.9485        50\n",
            "           1     0.9245    0.9800    0.9515        50\n",
            "\n",
            "    accuracy                         0.9500       100\n",
            "   macro avg     0.9516    0.9500    0.9500       100\n",
            "weighted avg     0.9516    0.9500    0.9500       100\n",
            "\n",
            "\n",
            "   =   =   =   =   =   =\n",
            "4️  PREDICCIÓN DE RENDIMIENTO DE COMBUSTIBLE\n",
            "   =   =   =   =   =   =\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Error cuadrático medio (MSE): 106.229\n",
            "Ejemplo de predicciones:\n",
            "  Verdadero=-335.45, Predicho=-334.97\n",
            "  Verdadero=22.36, Predicho=22.15\n",
            "  Verdadero=129.31, Predicho=134.74\n",
            "  Verdadero=100.05, Predicho=106.29\n",
            "  Verdadero=161.61, Predicho=157.76\n",
            "\n",
            "   =   =   =   =   =   =\n",
            "5️  PREDICCIÓN DE POPULARIDAD DE UNA CANCIÓN\n",
            "   =   =   =   =   =   =\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Error cuadrático medio (MSE): 35.225\n",
            "Ejemplo de predicciones:\n",
            "  Verdadero=32.92, Predicho=35.20\n",
            "  Verdadero=13.78, Predicho=18.69\n",
            "  Verdadero=17.67, Predicho=26.67\n",
            "  Verdadero=2.36, Predicho=10.80\n",
            "  Verdadero=3.54, Predicho=14.13\n",
            "\n",
            " Todos los modelos fueron entrenados y evaluados correctamente.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Redes Neuronales Multicapa con TensorFlow\n",
        "===================================================\n",
        "Ejemplos prácticos divididos en cinco partes:\n",
        "\n",
        "1️ XOR (problema clásico de aprendizaje no lineal)\n",
        "2️ Clasificación de la flor de Iris\n",
        "3️ Clasificación de un candidato a un empleo\n",
        "4️ Predicción del rendimiento de combustibles\n",
        "5️ Predicción de popularidad de una canción\n",
        "\n",
        "Librerías: TensorFlow, NumPy, Scikit-Learn\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.datasets import load_iris, make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "\n",
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# === Función auxiliar para crear el modelo MLP # ===\n",
        "def build_mlp(input_dim, hidden_layers, output_units, output_activation=None):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "    for units in hidden_layers:\n",
        "        model.add(layers.Dense(units, activation='relu'))\n",
        "    model.add(layers.Dense(output_units, activation=output_activation))\n",
        "    return model\n",
        "\n",
        "# === PARTE 1️ - XOR ===\n",
        "print(\"\\n   =  =  =  =  =  =\")\n",
        "print(\"1️  RED NEURONAL MULTICAPA - XOR\")\n",
        "print(\"  =  =  =  =  =  =\")\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=float)\n",
        "y = np.array([0,1,1,0], dtype=float)\n",
        "\n",
        "model_xor = build_mlp(2, (4,), 1, 'sigmoid')\n",
        "model_xor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_xor.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "preds = (model_xor.predict(X) > 0.5).astype(int)\n",
        "print(\"Entrenamiento completado \")\n",
        "print(\"Predicciones:\", preds.reshape(-1))\n",
        "print(\"Clases reales:\", y.astype(int))\n",
        "\n",
        "# === PARTE 2️ - CLASIFICACIÓN DE IRIS ===\n",
        "print(\"\\n   =   =   =   =   =   =\")\n",
        "print(\"2️  CLASIFICACIÓN DE LA FLOR DE IRIS\")\n",
        "print(\"   =   =   =   =   =   =\")\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1,1)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_ohe = encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_ohe, test_size=0.2, random_state=SEED)\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "model_iris = build_mlp(4, (64,32), 3, 'softmax')\n",
        "model_iris.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_iris.fit(X_train_s, y_train, epochs=150, batch_size=8, verbose=0, validation_data=(X_test_s, y_test))\n",
        "\n",
        "acc = model_iris.evaluate(X_test_s, y_test, verbose=0)[1]\n",
        "print(f\"Exactitud en prueba: {acc*100:.2f}%\")\n",
        "\n",
        "preds = np.argmax(model_iris.predict(X_test_s), axis=1)\n",
        "true = np.argmax(y_test, axis=1)\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(true, preds, target_names=iris.target_names))\n",
        "\n",
        "# === PARTE 3️ - CLASIFICACIÓN DE CANDIDATO A EMPLEO ===\n",
        "print(\"\\n   =   =   =   =   =   =\")\n",
        "print(\"3️  CLASIFICACIÓN DE UN CANDIDATO A UN EMPLEO\")\n",
        "print(\"   =   =   =   =   =   =\")\n",
        "\n",
        "X, y = make_classification(n_samples=500, n_features=4, n_informative=3, n_redundant=0, random_state=SEED)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "model_job = build_mlp(4, (32,16), 1, 'sigmoid')\n",
        "model_job.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_job.fit(X_train_s, y_train, epochs=100, verbose=0)\n",
        "\n",
        "acc = model_job.evaluate(X_test_s, y_test, verbose=0)[1]\n",
        "print(f\"Exactitud en prueba: {acc*100:.2f}%\")\n",
        "\n",
        "preds = (model_job.predict(X_test_s) > 0.5).astype(int)\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "\n",
        "# === PARTE 4️ - PREDICCIÓN DE RENDIMIENTO DE COMBUSTIBLE ===\n",
        "print(\"\\n   =   =   =   =   =   =\")\n",
        "print(\"4️  PREDICCIÓN DE RENDIMIENTO DE COMBUSTIBLE\")\n",
        "print(\"   =   =   =   =   =   =\")\n",
        "\n",
        "X, y = make_regression(n_samples=600, n_features=5, n_informative=4, noise=8.0, random_state=SEED)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "model_fuel = build_mlp(5, (64,32), 1)\n",
        "model_fuel.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model_fuel.fit(X_train_s, y_train, epochs=150, verbose=0)\n",
        "\n",
        "preds = model_fuel.predict(X_test_s)\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "print(f\"Error cuadrático medio (MSE): {mse:.3f}\")\n",
        "print(\"Ejemplo de predicciones:\")\n",
        "for t,p in list(zip(y_test[:5], preds[:5].reshape(-1))):\n",
        "    print(f\"  Verdadero={t:.2f}, Predicho={p:.2f}\")\n",
        "\n",
        "# === PARTE 5️ - POPULARIDAD DE UNA CANCIÓN ===\n",
        "print(\"\\n   =   =   =   =   =   =\")\n",
        "print(\"5️  PREDICCIÓN DE POPULARIDAD DE UNA CANCIÓN\")\n",
        "print(\"   =   =   =   =   =   =\")\n",
        "\n",
        "n = 800\n",
        "rng = np.random.RandomState(SEED)\n",
        "tempo = rng.normal(120, 15, size=n)\n",
        "dance = rng.uniform(0, 1, size=n)\n",
        "energy = rng.uniform(0, 1, size=n)\n",
        "duration = rng.normal(210, 40, size=n)\n",
        "acoustic = rng.uniform(0, 1, size=n)\n",
        "\n",
        "X = np.vstack([tempo, dance, energy, duration, acoustic]).T\n",
        "y = (0.02*(tempo-80) + 30*dance + 25*energy - 0.01*(duration-180) - 10*acoustic + rng.normal(0,5,size=n))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "model_song = build_mlp(5, (64,32), 1)\n",
        "model_song.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model_song.fit(X_train_s, y_train, epochs=200, verbose=0)\n",
        "\n",
        "preds = model_song.predict(X_test_s)\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "print(f\"Error cuadrático medio (MSE): {mse:.3f}\")\n",
        "print(\"Ejemplo de predicciones:\")\n",
        "for t,p in list(zip(y_test[:5], preds[:5].reshape(-1))):\n",
        "    print(f\"  Verdadero={t:.2f}, Predicho={p:.2f}\")\n",
        "\n",
        "print(\"\\n Todos los modelos fueron entrenados y evaluados correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REDES NEURONALES MULTICAPA (MLP) CON TENSORFLOW/KERAS\n",
        "# Autor: Pamela Figueroa y Mina Soto\n",
        "# Descripción: Este archivo muestra cinco ejemplos de redes multicapa con TensorFlow.\n",
        "# Cada sección está traducida y explicada en español para comprensión y exposición.\n",
        "\n",
        "# ===============================================================\n",
        "# Importar librerías necesarias\n",
        "# ===============================================================\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# ===============================================================\n",
        "# Parte 1: Problema XOR\n",
        "# ===============================================================\n",
        "print(\"\\n=========================\")\n",
        "print(\" PARTE 1: PROBLEMA XOR\")\n",
        "print(\"=========================\")\n",
        "\n",
        "# Datos de entrada (X) y salida (y) del problema XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Definir el modelo\n",
        "modelo_xor = keras.Sequential([\n",
        "    keras.layers.Dense(8, activation='relu', input_shape=(2,)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo_xor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo_xor.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# Evaluar el modelo\n",
        "perdida, exactitud = modelo_xor.evaluate(X, y, verbose=0)\n",
        "print(f\"Precisión del modelo XOR: {exactitud*100:.2f}%\")\n",
        "\n",
        "# Ejemplo de predicciones\n",
        "print(\"Predicciones:\")\n",
        "print(X, \"→\", modelo_xor.predict(X).round())\n",
        "\n",
        "# ===============================================================\n",
        "# Parte 2: Clasificación de la Flor Iris\n",
        "# ===============================================================\n",
        "print(\"\\n===========================================\")\n",
        "print(\" PARTE 2: CLASIFICACIÓN DE LA FLOR IRIS\")\n",
        "print(\"===========================================\")\n",
        "\n",
        "# Cargar el dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_entren, X_prueba, y_entren, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar los datos\n",
        "escalador = StandardScaler()\n",
        "X_entren = escalador.fit_transform(X_entren)\n",
        "X_prueba = escalador.transform(X_prueba)\n",
        "\n",
        "# Crear el modelo\n",
        "modelo_iris = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar y entrenar\n",
        "modelo_iris.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "modelo_iris.fit(X_entren, y_entren, epochs=100, verbose=0)\n",
        "\n",
        "# Evaluar\n",
        "perdida, exactitud = modelo_iris.evaluate(X_prueba, y_prueba, verbose=0)\n",
        "print(f\"Precisión en la clasificación Iris: {exactitud*100:.2f}%\")\n",
        "\n",
        "# ===============================================================\n",
        "# Parte 3: Clasificación de un Candidato a Empleo\n",
        "# ===============================================================\n",
        "print(\"\\n=====================================================\")\n",
        "print(\" PARTE 3: CLASIFICACIÓN DE CANDIDATO A UN EMPLEO\")\n",
        "print(\"=====================================================\")\n",
        "\n",
        "# Crear un conjunto de datos sintético (experiencia, educación, habilidades)\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(200, 3)\n",
        "y = (X[:,0]*0.5 + X[:,1]*0.3 + X[:,2]*0.2 > 0.5).astype(int)\n",
        "\n",
        "# Dividir los datos\n",
        "X_entren, X_prueba, y_entren, y_prueba = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Definir el modelo\n",
        "modelo_empleo = keras.Sequential([\n",
        "    keras.layers.Dense(8, activation='relu', input_shape=(3,)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar y entrenar\n",
        "modelo_empleo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "modelo_empleo.fit(X_entren, y_entren, epochs=150, verbose=0)\n",
        "\n",
        "# Evaluar\n",
        "perdida, exactitud = modelo_empleo.evaluate(X_prueba, y_prueba, verbose=0)\n",
        "print(f\"Precisión del clasificador de empleo: {exactitud*100:.2f}%\")\n",
        "\n",
        "# ===============================================================\n",
        "#  Parte 4: Predicción de Rendimiento de Combustible\n",
        "# ===============================================================\n",
        "print(\"\\n==============================================\")\n",
        "print(\" PARTE 4: PREDICCIÓN DE RENDIMIENTO DE COMBUSTIBLE\")\n",
        "print(\"==============================================\")\n",
        "\n",
        "# Datos sintéticos (cilindros, peso, potencia)\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(300, 3)\n",
        "y = X[:,0]*10 + X[:,1]*20 + X[:,2]*15 + np.random.rand(300)*2\n",
        "\n",
        "X_entren, X_prueba, y_entren, y_prueba = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Modelo de regresión\n",
        "modelo_combustible = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(3,)),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "modelo_combustible.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "modelo_combustible.fit(X_entren, y_entren, epochs=150, verbose=0)\n",
        "\n",
        "# Evaluar\n",
        "perdida, error_medio = modelo_combustible.evaluate(X_prueba, y_prueba, verbose=0)\n",
        "print(f\"Error absoluto medio en predicción de combustible: {error_medio:.2f}\")\n",
        "\n",
        "# ===============================================================\n",
        "# Parte 5: Predicción de Popularidad de una Canción\n",
        "# ===============================================================\n",
        "print(\"\\n==============================================\")\n",
        "print(\" PARTE 5: PREDICCIÓN DE POPULARIDAD DE UNA CANCIÓN\")\n",
        "print(\"==============================================\")\n",
        "\n",
        "# Datos sintéticos (energía, baile, duración, acústica)\n",
        "np.random.seed(123)\n",
        "X = np.random.rand(400, 4)\n",
        "y = X[:,0]*40 + X[:,1]*30 + X[:,2]*20 + X[:,3]*10 + np.random.rand(400)*5\n",
        "\n",
        "X_entren, X_prueba, y_entren, y_prueba = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Modelo de regresión\n",
        "modelo_cancion = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "modelo_cancion.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "modelo_cancion.fit(X_entren, y_entren, epochs=150, verbose=0)\n",
        "\n",
        "# Evaluar\n",
        "perdida, error_medio = modelo_cancion.evaluate(X_prueba, y_prueba, verbose=0)\n",
        "print(f\"Error absoluto medio en popularidad: {error_medio:.2f}\")\n",
        "\n",
        "print(\"\\n Fin del programa: todos los modelos entrenados y evaluados correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7PqOc19ZaXH",
        "outputId": "56e3f76a-bc36-4eac-dbcc-38f4412902f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n",
            " PARTE 1: PROBLEMA XOR\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo XOR: 100.00%\n",
            "Predicciones:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]] → [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "\n",
            "===========================================\n",
            " PARTE 2: CLASIFICACIÓN DE LA FLOR IRIS\n",
            "===========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión en la clasificación Iris: 100.00%\n",
            "\n",
            "=====================================================\n",
            " PARTE 3: CLASIFICACIÓN DE CANDIDATO A UN EMPLEO\n",
            "=====================================================\n",
            "Precisión del clasificador de empleo: 87.50%\n",
            "\n",
            "==============================================\n",
            " PARTE 4: PREDICCIÓN DE RENDIMIENTO DE COMBUSTIBLE\n",
            "==============================================\n",
            "Error absoluto medio en predicción de combustible: 0.57\n",
            "\n",
            "==============================================\n",
            " PARTE 5: PREDICCIÓN DE POPULARIDAD DE UNA CANCIÓN\n",
            "==============================================\n",
            "Error absoluto medio en popularidad: 4.11\n",
            "\n",
            " Fin del programa: todos los modelos entrenados y evaluados correctamente.\n"
          ]
        }
      ]
    }
  ]
}